from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from pathlib import Path

# ğŸ”§ Crear sesiÃ³n Spark con soporte Delta Lake
builder = SparkSession.builder \
    .appName("Visualizacion_KPIs_MeteoGalicia") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

# ğŸ“ Rutas absolutas a los KPIs
base_path = Path(__file__).resolve().parents[2]  # Ajusta segÃºn tu estructura
kpi_base_path = base_path / "data" / "exploitation" / "meteogalicia_kpis"
kpi_prov_path = kpi_base_path / "estaciones_por_provincia"
kpi_concello_path = kpi_base_path / "estaciones_por_concello"

# ğŸ“¥ Leer KPIs en formato Delta
kpi_prov = spark.read.format("delta").load(str(kpi_prov_path))
kpi_concello = spark.read.format("delta").load(str(kpi_concello_path))

# ğŸ‘€ Mostrar resultados
print("â–¶ï¸ NÃºmero de estaciones por provincia:")
kpi_prov.show(truncate=False)

print("\nâ–¶ï¸ NÃºmero de estaciones por concello:")
kpi_concello.show(50, truncate=False)  # Cambia el 50 por mÃ¡s/menos si necesitas







