from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from pathlib import Path

# 🔧 Crear sesión Spark con soporte Delta Lake
builder = SparkSession.builder \
    .appName("Visualizacion_KPIs_MeteoGalicia") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

# 📁 Rutas absolutas a los KPIs
base_path = Path(__file__).resolve().parents[2]  # Ajusta según tu estructura
kpi_base_path = base_path / "data" / "exploitation" / "meteogalicia_kpis"
kpi_prov_path = kpi_base_path / "estaciones_por_provincia"
kpi_concello_path = kpi_base_path / "estaciones_por_concello"

# 📥 Leer KPIs en formato Delta
kpi_prov = spark.read.format("delta").load(str(kpi_prov_path))
kpi_concello = spark.read.format("delta").load(str(kpi_concello_path))

# 👀 Mostrar resultados
print("▶️ Número de estaciones por provincia:")
kpi_prov.show(truncate=False)

print("\n▶️ Número de estaciones por concello:")
kpi_concello.show(50, truncate=False)  # Cambia el 50 por más/menos si necesitas







